"""
agent/clova_mcp_v3.py - v2 + Analyzer í†µí•©

v2 ëŒ€ë¹„ ì¶”ê°€:
- AnalyzerNode: ì‚¬ìš©ì ê°ì •/í˜¸ê°ë„ ë¶„ì„ (LLM 1íšŒ ì¶”ê°€)

êµ¬ì¡°:
  START â†’ context_builder â†’ analyzer â†’ agent â†” tools â†’ memory_manager â†’ END

íŠ¹ì§•:
1. context_builder: ìë™ ê¸°ì–µ ê²€ìƒ‰ + ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (LLM ì—†ìŒ)
2. analyzer: ê°ì •/í˜¸ê°ë„ ë¶„ì„ (LLM 1íšŒ)
3. agent: ë„êµ¬ ì‚¬ìš© + ìµœì¢… ì‘ë‹µ (LLM 1íšŒ)
4. ì´ LLM í˜¸ì¶œ: 2íšŒ (analyzer + agent)
"""

import os
import sys
import asyncio
import uuid
import re
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
from dotenv import load_dotenv

# ìƒìœ„ ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# LangGraph/LangChain ì„í¬íŠ¸
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage

# MCP í´ë¼ì´ì–¸íŠ¸
try:
    from langchain_mcp_adapters.client import MultiServerMCPClient
    HAS_MCP = True
except ImportError:
    print("Warning: langchain-mcp-adapters not found. MCP features disabled.")
    HAS_MCP = False

# Clova LLM
try:
    from langchain_naver import ChatClovaX
    HAS_CLOVA = True
except ImportError:
    print("Warning: langchain-naver not found.")
    HAS_CLOVA = False

from langchain_core.utils.function_calling import convert_to_openai_tool

# ë¡œì»¬ ëª¨ë“ˆ
from memory import create_memory_system
from nodes import (
    ContextBuilderNode,
    ContextBuilderConfig,
    AnalyzerNode,
    AnalyzerConfig,
    MemoryManagerNode,
    MemoryManagerConfig
)
from graph import AgentState, AgentNode
from agent.persona_logic import PersonaManager


# ============================================================
# í™˜ê²½ ì„¤ì •
# ============================================================

load_dotenv()

API_KEY = os.getenv("NCP_CLOVASTUDIO_API_KEY", "")
REQUEST_ID = os.getenv("NCP_CLOVASTUDIO_REQUEST_ID", "")
HOST = 'clovastudio.stream.ntruss.com'
SLACK_MCP_URL = os.getenv("SLACK_MCP_URL")

# MCP ì„œë²„ ì„¤ì •
MCP_SERVERS = {
    "naver_search": {
        "url": "http://127.0.0.1:8000/mcp/",
        "transport": "streamable_http"
    },
    "discord-mcp": {
        "url": "http://localhost:8001/mcp/",
        "transport": "streamable_http"
    },
    "playwright-mcp": {
        "url": "http://localhost:8931/mcp",
        "transport": "streamable_http",
    }
}

if SLACK_MCP_URL:
    MCP_SERVERS["slack-mcp"] = {
        "url": SLACK_MCP_URL,
        "transport": "sse",
    }

# ë¯¼ê°í•œ ë„êµ¬ ëª©ë¡
SENSITIVE_TOOL_NAMES = {
    "send_message",
    "read_messages",
    "add_reaction",
    "channels_list",
    "conversations_history",
    "conversations_add_message"
}


# ============================================================
# Tool Schema Fix for Clova
# ============================================================

def _recursive_fix_properties(schema: Any):
    if isinstance(schema, dict):
        if schema.get("type") == "object" and "properties" not in schema:
            schema["properties"] = {}
        for key, value in schema.items():
            _recursive_fix_properties(value)
    elif isinstance(schema, list):
        for item in schema:
            _recursive_fix_properties(item)


def fix_clova_tool_schema(tools):
    fixed_tools = []
    for tool in tools:
        try:
            schema = convert_to_openai_tool(tool)
        except Exception:
            continue
        if "function" in schema:
            func = schema["function"]
            if "parameters" not in func or not func["parameters"]:
                func["parameters"] = {"type": "object", "properties": {}, "required": []}
            if "properties" not in func["parameters"]:
                func["parameters"]["properties"] = {}
            if not func["parameters"]["properties"]:
                func["parameters"]["properties"] = {"_dummy": {"type": "string", "description": "Ignore"}}
            _recursive_fix_properties(func["parameters"])
        fixed_tools.append(schema)
    return fixed_tools


# ============================================================
# MCP ë„êµ¬ ë¡œë“œ
# ============================================================

async def load_mcp_tools() -> tuple[List, List]:
    if not HAS_MCP:
        return [], []

    safe_tools = []
    sensitive_tools = []

    try:
        client = MultiServerMCPClient(MCP_SERVERS)
        all_tools = await client.get_tools()

        for t in all_tools:
            name = t.name if hasattr(t, 'name') else str(t)
            if name in SENSITIVE_TOOL_NAMES:
                sensitive_tools.append(t)
            else:
                safe_tools.append(t)

        print(f"[MCP] Loaded {len(safe_tools)} safe tools, {len(sensitive_tools)} sensitive tools")

    except Exception as e:
        print(f"[MCP] Error loading tools: {e}")

    return safe_tools, sensitive_tools


# ============================================================
# ë¼ìš°íŒ… í•¨ìˆ˜
# ============================================================

def route_after_agent(state: AgentState) -> str:
    """Agent ì‘ë‹µ í›„ ë¼ìš°íŒ…"""
    messages = state.get("messages", [])

    if not messages:
        return "memory_manager"

    last_message = messages[-1]

    if not isinstance(last_message, AIMessage):
        return "memory_manager"

    tool_calls = getattr(last_message, "tool_calls", None)

    if not tool_calls:
        return "memory_manager"

    called_names = [tc.get("name", "") for tc in tool_calls]

    if any(name in SENSITIVE_TOOL_NAMES for name in called_names):
        return "sensitive_tools"

    return "safe_tools"
# ============================================================
# HITL
# ============================================================
async def execute_graph_with_hitl(graph, inputs, config):
    """
    HITL ì²˜ë¦¬ë¥¼ í¬í•¨í•œ ê·¸ë˜í”„ ì‹¤í–‰ í•¨ìˆ˜
    """
    current_inputs = inputs

    while True:
        should_break_execution = False
        
        # astreamì„ í†µí•´ ë…¸ë“œë³„ ì—…ë°ì´íŠ¸ë¥¼ ì¶”ì 
        async for chunk in graph.astream(current_inputs, config=config, stream_mode="updates"):
            for node_name, output in chunk.items():
                if node_name == "agent":
                    # Agentê°€ ì‘ë‹µì„ ìƒì„±í•œ ê²½ìš°
                    if "messages" in output and output["messages"]:
                        last_msg = output["messages"][-1]
                        
                        # ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸
                        if hasattr(last_msg, "tool_calls") and last_msg.tool_calls:
                            tool_names = [tc["name"] for tc in last_msg.tool_calls]
                            
                            # ë¯¼ê°í•œ ë„êµ¬ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ìŠ¹ì¸ ì ˆì°¨ ì§„í–‰
                            if any(name in SENSITIVE_TOOL_NAMES for name in tool_names):
                                print("\n" + "!" * 30)
                                print("ğŸš¨ [ë³´ì•ˆ] ë¯¼ê°í•œ ë„êµ¬ ì‹¤í–‰ ìŠ¹ì¸ ìš”ì²­")
                                for tc in last_msg.tool_calls:
                                    print(f"ğŸ› ï¸  ì‹¤í–‰ ë„êµ¬: {tc['name']}\n   ë§¤ê°œë³€ìˆ˜: {tc['args']}")
                                
                                approval = input("\nìŠ¹ì¸í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()

                                if approval != 'y':
                                    print("âŒ ì‚¬ìš©ìê°€ ì‹¤í–‰ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤.")
                                    rejection_msgs = [
                                        ToolMessage(
                                            tool_call_id=tc['id'],
                                            content="ì‚¬ìš©ìê°€ ì´ ì‘ì—…ì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ëŒ€ì•ˆì„ ì œì‹œí•˜ê±°ë‚˜ ê±°ë¶€ ì‚¬ì‹¤ì„ ì•Œë¦¬ì„¸ìš”."
                                        ) for tc in last_msg.tool_calls
                                    ]
                                    # ê±°ë¶€ ë©”ì‹œì§€ë¥¼ ê°•ì œë¡œ ìƒíƒœì— ì£¼ì… (sensitive_tools ë…¸ë“œê°€ ì‹¤í–‰ëœ ê²ƒì²˜ëŸ¼)
                                    await graph.aupdate_state(
                                        config,
                                        {"messages": rejection_msgs},
                                        as_node="sensitive_tools"
                                    )
                                    # ì…ë ¥ì„ Noneìœ¼ë¡œ ë§Œë“¤ê³  ë‹¤ìŒ ë£¨í”„ì—ì„œ Agentê°€ ê±°ë¶€ ìƒí™©ì„ ì¸ì§€í•˜ê²Œ í•¨
                                    current_inputs = None
                                    should_break_execution = True
                                    break
                                else:
                                    print("âœ… ìŠ¹ì¸ë¨. ì‘ì—…ì„ ì§„í–‰í•©ë‹ˆë‹¤...")

                elif node_name == "memory_manager":
                    # ìµœì¢… ì™„ë£Œ ë‹¨ê³„
                    pass

            if should_break_execution:
                break

        # ë£¨í”„ ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        current_state = await graph.aget_state(config)
        if not current_state.next:
            return True
        
        current_inputs = None # ì—°ì† ì‹¤í–‰ì„ ìœ„í•´ ì…ë ¥ ì´ˆê¸°í™”




# ============================================================
# ê·¸ë˜í”„ ìƒì„± (v3: context_builder + analyzer + agent)
# ============================================================

def create_graph_v3(
    llm,
    analyzer_llm,
    safe_tools: List,
    sensitive_tools: List,
    tool_fixer,
    retriever,
    repository,
    summarizer,
    window_trimmer,
    persona_manager_cls,
    checkpointer=None,
    context_config=None,
    analyzer_config=None,
    memory_config=None
):
    """
    v3 ê·¸ë˜í”„ ìƒì„±: context_builder + analyzer + agent

    v2 ëŒ€ë¹„:
    - analyzer ë…¸ë“œ ì¶”ê°€ (ê°ì •/í˜¸ê°ë„ ë¶„ì„)
    """
    all_tools = safe_tools + sensitive_tools

    # ë…¸ë“œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    context_builder = ContextBuilderNode(
        retriever=retriever,
        persona_manager_cls=persona_manager_cls,
        config=context_config
    )

    analyzer = AnalyzerNode(
        llm=analyzer_llm,
        config=analyzer_config
    )

    agent = AgentNode(
        llm=llm,
        tools=all_tools,
        tool_fixer=tool_fixer
    )

    safe_tool_node = ToolNode(safe_tools)
    sensitive_tool_node = ToolNode(sensitive_tools)

    memory_manager = MemoryManagerNode(
        window_trimmer=window_trimmer,
        summarizer=summarizer,
        repository=repository,
        config=memory_config
    )

    # ê·¸ë˜í”„ ì •ì˜
    workflow = StateGraph(AgentState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("context_builder", context_builder)
    workflow.add_node("analyzer", analyzer)
    workflow.add_node("agent", agent)
    workflow.add_node("safe_tools", safe_tool_node)
    workflow.add_node("sensitive_tools", sensitive_tool_node)
    workflow.add_node("memory_manager", memory_manager)

    # ì—£ì§€ ì •ì˜: analyzer â†’ context_builder â†’ agent
    # analyzerê°€ ë¨¼ì € ê°ì • ë¶„ì„ â†’ context_builderê°€ ë¶„ì„ ê²°ê³¼ ë°˜ì˜í•œ system_prompt ìƒì„±
    workflow.add_edge(START, "analyzer")
    workflow.add_edge("analyzer", "context_builder")
    workflow.add_edge("context_builder", "agent")

    # ì¡°ê±´ë¶€ ë¼ìš°íŒ…
    workflow.add_conditional_edges(
        "agent",
        route_after_agent,
        {
            "safe_tools": "safe_tools",
            "sensitive_tools": "sensitive_tools",
            "memory_manager": "memory_manager"
        }
    )

    # ë„êµ¬ ì‹¤í–‰ í›„ agentë¡œ ë³µê·€
    workflow.add_edge("safe_tools", "agent")
    workflow.add_edge("sensitive_tools", "agent")
    workflow.add_edge("memory_manager", END)

    # ì»´íŒŒì¼
    compile_kwargs = {}
    if checkpointer:
        compile_kwargs["checkpointer"] = checkpointer
    
    # HITLì„ ìœ„í•œ ì¸í„°ëŸ½íŠ¸ ì¶”ê°€
    return workflow.compile(
        **compile_kwargs,
        interrupt_before=["sensitive_tools"] 
    )


# ============================================================
# ê·¸ë˜í”„ ìƒì„± í—¬í¼
# ============================================================

async def create_agent_graph(checkpointer):
    """v3 ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    if not HAS_CLOVA or not API_KEY:
        raise ValueError("Clova API key not configured")

    # 1. ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ìƒì„±
    print("[Init] Creating memory system...")
    memory_system = create_memory_system(
        api_key=API_KEY,
        request_id=REQUEST_ID,
        host=HOST,
        persist_directory="./chroma_db"
    )

    # 2. MCP ë„êµ¬ ë¡œë“œ
    print("[Init] Loading MCP tools...")
    safe_tools, sensitive_tools = await load_mcp_tools()

    # 3. LLM ìƒì„±
    print("[Init] Creating LLMs...")

    # Agentìš© LLM
    agent_llm = ChatClovaX(
        model="HCX-005",
        temperature=0.5,
        max_tokens=4096
    )

    # Analyzerìš© LLM (ë” ë‚®ì€ temperature)
    analyzer_llm = ChatClovaX(
        model="HCX-005",
        temperature=0.1,
        max_tokens=1024
    )

    print(f"[Init] Total {len(safe_tools) + len(sensitive_tools)} tools loaded")

    # 4. ê·¸ë˜í”„ ìƒì„±
    print("[Init] Building v3 graph (with analyzer)...")
    graph = create_graph_v3(
        llm=agent_llm,
        analyzer_llm=analyzer_llm,
        safe_tools=safe_tools,
        sensitive_tools=sensitive_tools,
        tool_fixer=fix_clova_tool_schema,
        retriever=memory_system["retriever"],
        repository=memory_system["repository"],
        summarizer=memory_system["summarizer"],
        window_trimmer=memory_system["window_trimmer"],
        persona_manager_cls=PersonaManager,
        checkpointer=checkpointer,
        context_config=ContextBuilderConfig(
            max_memories=5,
            similarity_threshold=0.7
        ),
        analyzer_config=AnalyzerConfig(
            max_intimacy_change=5,
            temperature=0.1,
            max_tokens=512
        ),
        memory_config=MemoryManagerConfig(
            token_threshold=8192,
            max_tokens_after_trim=4000
        )
    )

    print("[Init] v3 Graph ready!")
    return graph

# ============================================================
# ì„¸ì…˜ê´€ë¦¬
# ============================================================

def get_last_thread_id():
    if os.path.exists("last_session.txt"):
        with open("last_session.txt", "r") as f:
            return f.read().strip()
    return "mcp_default_session"

# ì„¸ì…˜ ID ì €ì¥ í•¨ìˆ˜
def save_last_thread_id(thread_id):
    with open("last_session.txt", "w") as f:
        f.write(thread_id)


# ============================================================
# ì„¸ì…˜ ì‹¤í–‰
# ============================================================

async def run_session():
    """ëŒ€í™” ì„¸ì…˜ ì‹¤í–‰"""

    print("\n" + "=" * 60)
    print("  MCP Agent v3 (with Analyzer)")
    print("  êµ¬ì¡°: context_builder â†’ analyzer â†’ agent â†” tools")
    print("=" * 60)
    print("\nëª…ë ¹ì–´: /status, /boost, /reset, /tools, /quit\n")

    async with AsyncSqliteSaver.from_conn_string("persona_mcp_v3.sqlite") as checkpointer:
        try:
            graph = await create_agent_graph(checkpointer)
        except Exception as e:
            print(f"Error creating graph: {e}")
            return
        


        current_thread_id = get_last_thread_id()
        config = {
            "configurable": {
                "thread_id": current_thread_id
            }
        }

        user_profile = {
            "nickname": "",
            "relation_type": "ì¹œí•œ ì¹œêµ¬",
            "first_meet_date": datetime.now().isoformat()
        }

        while True:
            try:
                current = await graph.aget_state(config)
                current_vals = current.values if current.values else {}
                user_input = input("\n You: ").strip()

                if not user_input:
                    continue

                # ëª…ë ¹ì–´ ì²˜ë¦¬
                if user_input.lower() == "/quit":
                    print(" ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                    break

                if user_input.lower() == "/status":
                    print("\n ì„¸ì…˜ ìƒíƒœ:")
                    print(f"  Thread ID: mcp_session_v3")
                    print(f"  Profile: {current_vals.get('user_profile', user_profile)}")
                    print(f"  Intimacy Level: {current_vals.get('intimacy_level', 0)}")
                    print(f"  Current Emotion: {current_vals.get('current_emotion', 'N/A')}")
                    continue

                if user_input.lower() == "/boost":
                    level = current_vals.get("intimacy_level", 0)
                    await graph.aupdate_state(config, {"intimacy_level": min(100, level + 10)}, as_node="memory_manager")
                    print(f"ì¹œë°€ë„ ì¦ê°€: {level} -> {min(100, level + 10)}")
                    continue

                if user_input == "/reset":
                    new_thread_id = f"mcp_session_v3_{uuid.uuid4().hex[:8]}"
                    new_id = f"mcp_session_{uuid.uuid4().hex[:8]}"
                    config["configurable"]["thread_id"] = new_id
                    save_last_thread_id(new_id) # íŒŒì¼ì— ìƒˆ ID ê¸°ë¡
                    user_profile = {"nickname": "", "relation_type": "AI ë¹„ì„œ"}

                    print(f"âœ¨ ìƒˆ ì„¸ì…˜ ì‹œì‘: {new_id}")

            


                    print(f"ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ (ìƒˆ ì„¸ì…˜: {new_thread_id})")
                    continue

                if user_input == "/tools":
                    safe_tools, sensitive_tools = await load_mcp_tools()
                    print(f"[Safe Tools]: {[t.name for t in safe_tools]}")
                    print(f"[Sensitive Tools]: {[t.name for t in sensitive_tools]}")
                    continue

                current = await graph.aget_state(config)
                current_vals = current.values if current.values else {}

                state = {
                    "messages": [HumanMessage(content=user_input)],
                    "user_id": "default",
                    "intimacy_level": current_vals.get("intimacy_level", 0),
                    "user_profile": current_vals.get("user_profile", user_profile),
                    "current_emotion": current_vals.get("current_emotion", ""),
                    "system_prompt": "",
                    "retrieved_memories": [],
                    "context_metadata": {}
                }

                print("\n AI: ", end="", flush=True)



                await execute_graph_with_hitl(graph, state, config)

                # 3. [ë³€ê²½] ì‹¤í–‰ì´ ì™„ë£Œëœ í›„ì˜ ìµœì¢… ìƒíƒœë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                final_state = await graph.aget_state(config)
                result = final_state.values  # ê¸°ì¡´ì˜ result ë³€ìˆ˜ ì—­í• ì„ ìˆ˜í–‰
                # 4. ì‘ë‹µ ì²˜ë¦¬ ë° ì¶œë ¥ ë¡œì§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                if result.get("messages"):
                    # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ë¥¼ ì°¾ì•„ ë‹µë³€ê³¼ ì¹œë°€ë„ ë³€í™”ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
                    for msg in reversed(result["messages"]):
                        if isinstance(msg, AIMessage) and msg.content:
                            try:
                                json_match = re.search(r'\{[^{}]*"ë‹µë³€"[^{}]*\}', msg.content)
                                if json_match:
                                    response_data = json.loads(json_match.group())

                                    # í˜¸ê°ë„ ë³€í™”
                                    affinity_change = response_data.get("í˜¸ê°ë„ë³€í™”", 0)
                                    if affinity_change:
                                        current_intimacy = current_vals.get("intimacy_level", 0)
                                        new_intimacy = max(0, min(100, current_intimacy + affinity_change))
                                        await graph.aupdate_state(config, {"intimacy_level": new_intimacy}, as_node="memory_manager")
                                        print(f"   ì¹œë°€ë„: {current_intimacy} -> {new_intimacy}")

                                    # ë‹‰ë„¤ì„ ë³€í™”
                                    new_nickname = response_data.get("nickname", "")
                                    current_profile = current_vals.get("user_profile", user_profile)
                                    if new_nickname and new_nickname != current_profile.get("nickname", ""):
                                        updated_profile = {**current_profile, "nickname": new_nickname}
                                        await graph.aupdate_state(config, {"user_profile": updated_profile}, as_node="memory_manager")
                                        print(f"   ë‹‰ë„¤ì„ ì„¤ì •: '{new_nickname}'")

                                    # ê´€ê³„ íƒ€ì… ë³€í™”
                                    new_relation = response_data.get("relation", "")
                                    if new_relation and new_relation != current_profile.get("relation_type", ""):
                                        updated_profile = current_vals.get("user_profile", user_profile)
                                        updated_profile = {**updated_profile, "relation_type": new_relation}
                                        await graph.aupdate_state(config, {"user_profile": updated_profile}, as_node="memory_manager")
                                        print(f"   ê´€ê³„ íƒ€ì…: '{new_relation}'")

                                    # ê°ì • ìƒíƒœ (Analyzerì—ì„œ ì´ë¯¸ ì—…ë°ì´íŠ¸í–ˆì§€ë§Œ ì‘ë‹µì—ì„œë„ ì²´í¬)
                                    new_emotion = response_data.get("ê°ì •", "")
                                    if new_emotion:
                                        await graph.aupdate_state(config, {"current_emotion": new_emotion}, as_node="memory_manager")
                                        print(f"   ê°ì •: '{new_emotion}'")

                                    answer = response_data.get("ë‹µë³€", msg.content)
                                    print(answer)
                                else:
                                    # JSON í˜•ì‹ì´ ì•„ë‹ ê²½ìš° ì¼ë°˜ ì¶œë ¥
                                    if not msg.tool_calls: # ë„êµ¬ í˜¸ì¶œ ë©”ì‹œì§€ëŠ” ì¶œë ¥ ì œì™¸
                                        print(f"\nAI: {msg.content}")
                            except (json.JSONDecodeError, Exception):
                                if not msg.tool_calls:
                                    print(f"\nAI: {msg.content}")
                            break

                # 5. ë©”íƒ€ë°ì´í„° ë° Analyzer ê²°ê³¼ ì¶œë ¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                metadata = result.get("context_metadata", {})
                if metadata.get("memories_found", 0) > 0:
                    print(f"   ({metadata['memories_found']}ê°œì˜ ê´€ë ¨ ê¸°ì–µ í™œìš©ë¨)")

                emotion = result.get("current_emotion", "")
                if emotion:
                    print(f"   [Analyzer] í˜„ì¬ ê°ì •: {emotion}")
                
            except KeyboardInterrupt:
                print("\n\n ì•ˆë…•íˆ ê°€ì„¸ìš”!")
                break
            except Exception as e:
                print(f"\n Error: {e}")
                import traceback
                traceback.print_exc()

# def run():
#     asyncio.run(run_session())
# ============================================================
# ë©”ì¸//
# ============================================================

if __name__ == "__main__":
    # run()
    asyncio.run(run_session())